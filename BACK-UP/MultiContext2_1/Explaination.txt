------------------------------------------------------------
1. app2.py
------------------------------------------------------------
Purpose:
- Extracts FAQs from websites and prepares high-quality training data for AI chatbot fine-tuning.
- Saves all extracted FAQ data as domain-specific JSONL files in the FineTuning folder (e.g., FineTuning/education_training.jsonl).

Workflow:
- Crawls specified websites or FAQ pages to collect Q&A pairs.
- Uses Natural Language Processing (NLP) to clean and structure the data.
- Tags each FAQ with domain (hospitality, education, technical, etc.), tone (welcoming, technical, etc.), and intent (support, information, etc.).
- Outputs training data in OpenAI’s JSONL format, ready for model fine-tuning.
- Saves all processed FAQ data to the FineTuning folder for auditing and debugging.

Key Features:
- Ensures each FAQ is properly categorized for adaptive chatbot training.
- Maintains data integrity and avoids duplication.
- Imports shared logic from shared_config.py for consistency.
- Output pipeline: all extracted data is saved in FineTuning/<domain>.jsonl for review and fine-tuning.

------------------------------------------------------------
2. check_and_tune.py
------------------------------------------------------------
Purpose:
- Fine-tunes an OpenAI model using a selected training file and provides an interactive chatbot for validation.
- Saves fine-tuned model IDs and related artifacts in the FineTuning folder, next to the training file (e.g., FineTuning/education_training_model_id.txt).

Workflow:
- Loads a training file (JSONL) from the FineTuning folder and uploads it to OpenAI for fine-tuning.
- Monitors the fine-tuning job status (pending, validating_files, queued, running, succeeded, failed, cancelled).
- Saves the resulting model ID for future use and reference in the FineTuning folder.
- Launches a chatbot that uses the fine-tuned model to answer user queries interactively.
- Adapts responses based on domain, tone, and intent detected from the user’s message.
- Saves all fine-tuning and validation steps to the FineTuning folder for auditing and debugging.

Key Features:
- Uses logging for clear status updates and error handling.
- Reads/writes model IDs next to training files for easy management.
- Imports shared logic for NLP, prompt generation, and analysis.
- Supports domain-specific validation (hospitality, education, technical, etc.).
- Output pipeline: all model IDs and fine-tuning artifacts are saved in FineTuning for traceability.

------------------------------------------------------------
3. multimodel.py
------------------------------------------------------------
Purpose:
- Runs a multi-model ensemble chatbot, allowing you to query several fine-tuned models per turn and select the best response.
- Logs each chat turn, model responses, and accuracy scores to analysis/chatbot_logs.jsonl.

Workflow:
- Loads all available fine-tuned model IDs from the FineTuning/ folder.
- For each user message, sends the query to multiple models in parallel using threads.
- Scores and compares responses using keyword overlap and relevance.
- Returns the best answer, with options to view all candidate responses.
- Supports chat commands to control which/how many models are used per turn (/models, /use key1,key2, /k N, /all, /both, /exit).
- Logs each chat turn and model scoring to the analysis/ folder.

Key Features:
- Ensemble approach: combines strengths of multiple models (hospitality, education, technical, etc.).
- Parallel processing for speed and efficiency.
- Advanced routing and scoring logic for best answer selection.
- Highly flexible—ideal for benchmarking, hybrid support, or maximizing answer quality.
- Analysis pipeline: logs all chatbot interactions and scoring.

------------------------------------------------------------
4. shared_config.py
------------------------------------------------------------
Purpose:
- Provides shared configuration, NLP tools, and utility functions for all scripts in the project.
- Optionally logs advanced analysis results to analysis/analysis_result.jsonl.

Workflow:
- Defines key dictionaries for domain/tone/intent mapping (e.g., TOPIC_TONE_MAP, CONTEXTS).
- Loads and configures the SentimentIntensityAnalyzer (SIA) for tone detection.
- Implements advanced topic and tone detection functions for analyzing FAQ content.
- Generates adaptive system prompts based on domain, tone, and persona.
- Centralizes logic for persona expansion and prompt customization.
- Optionally logs analysis results for debugging or research.

Key Features:
- Ensures consistent domain/tone/intent mapping across all scripts.
- Reduces code duplication by providing reusable functions and configuration.
- Supports advanced NLP analysis for better training data and chatbot responses.
- Easy to update: changes here propagate to all dependent scripts.
- Analysis pipeline: can log analysis results for traceability.

------------------------------------------------------------
General Workflow & Relationships
------------------------------------------------------------
1. shared_config.py → Provides shared logic and configuration for all scripts.
2. app2.py → Extracts and prepares training data, logs to analysis/faqs_extracted.jsonl.
3. check_and_tune.py → Fine-tunes a model and validates it interactively, logs to analysis/training_validation.log.
4. multimodel.py → Runs a multi-model chatbot, logs to analysis/chatbot_logs.jsonl.

------------------------------------------------------------
Best Practices & Recommendations
------------------------------------------------------------
- Data Integrity: Ensure each training file contains only relevant domain data (e.g., education FAQs in education_training.jsonl).
- Prompt Quality: Use domain-specific, professional system prompts for best results.
- Model Management: Save model IDs next to their training files for easy reuse.
- Cost Control: Use ensemble mode (multimodel.py) judiciously, as it increases API usage.
- Customization: You can tailor tone, persona, and domain mappings in shared_config.py for your business needs.
- Analysis: Review logs in the analysis/ folder for debugging, auditing, and improvement.

------------------------------------------------------------
Summary Table
------------------------------------------------------------
| File             | Main Function                       | Analysis Output File                | Who Should Use It         |
|------------------|-------------------------------------|-------------------------------------|---------------------------|
| app2.py          | FAQ extraction & training data prep | analysis/faqs_extracted.jsonl       | Data team, analysts       |
| check_and_tune.py| Fine-tune & validate single model   | analysis/training_validation.log    | ML engineers, QA, support |
| multimodel.py    | Multi-model ensemble chatbot        | analysis/chatbot_logs.jsonl         | Advanced users, R&D       |
| shared_config.py | Shared config & NLP utilities       | analysis/analysis_result.jsonl      | All developers            |

------------------------------------------------------------


Short Explaination
------------------------------------------------------------
- app2.py: “This script extracts FAQs from websites and prepares the training data for our AI chatbot. It ensures each answer is tagged with the right business domain, communication style, and user intent. All extracted data is logged for analysis.”
- check_and_tune.py: “This script fine-tunes our chatbot model using the prepared data and lets us test its responses interactively. It’s ideal for validating a single domain-specific model. All fine-tuning and validation steps are logged.”
- multimodel.py: “This advanced script lets us query multiple fine-tuned models at once, compare their answers, and select the best. It’s powerful for benchmarking and hybrid support, but uses more resources. All chatbot turns and scoring are logged.”
- shared_config.py: “This module provides all the shared configuration, NLP tools, and prompt logic for the project. It keeps our code DRY, consistent, and easy to maintain. Optionally logs advanced analysis results.”

------------------------------------------------------------
